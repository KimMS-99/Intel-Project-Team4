# pose_with_angles.py
import cv2
import math
import numpy as np
from ultralytics import YOLO

# üìå Î™®Îç∏ Í≤ΩÎ°úÏôÄ Ïπ¥Î©îÎùº ÏÜåÏä§
model_path = '/home/jetson/intel7_team4/test/pytorch_test/best.pt'
model = YOLO(model_path)
cap = cv2.VideoCapture(0)

# üìê Í∞ÅÎèÑ Í≥ÑÏÇ∞ Ìï®Ïàò
def calculate_angle(a, b, c):
    if None in (a, b, c):
        return None
    ang = math.degrees(
        math.atan2(c[1] - b[1], c[0] - b[0]) -
        math.atan2(a[1] - b[1], a[0] - b[0])
    )
    ang = abs(ang)
    if ang > 180:
        ang = 360 - ang
    return ang

# üîó Ïó∞Í≤∞Ìï† keypoint Ïåç (skeleton)
skeleton = [
    ('left_ear', 'left_eye'), ('left_eye', 'nose'), ('nose', 'right_eye'),
    ('right_eye', 'right_ear'), ('nose', 'neck1'),
    ('left_shoulder', 'left_arm'), ('right_shoulder', 'right_arm'),
    ('left_shoulder', 'neck2'), ('right_shoulder', 'neck2'),
    ('neck1', 'neck2'), ('neck2', 'back1'), ('back1', 'back2'), ('back2', 'waist'),
    ('waist', 'left_hip'), ('waist', 'right_hip'),
    ('left_hip', 'left_knee'), ('left_knee', 'left_ankle'),
    ('right_hip', 'right_knee'), ('right_knee', 'right_ankle')
]

# üî¢ YOLOv8 Í∏∞Î∞ò keypoint Ïù∏Îç±Ïä§ Îß§Ìïë (ÏÇ¨Ïö©Ïûê Î™®Îç∏Ïóê ÎßûÍ≤å Ï°∞Ï†ïÌïòÏÑ∏Ïöî)
keypoint_index = {
    'neck1': 0,
    'neck2': 1,
    'left_shoulder': 2,
    'right_shoulder': 3,
    'left_arm': 4,
    'right_arm': 5,
    'back1': 6,
    'back2': 7,
    'waist': 8,
    'left_hip': 9,
    'right_hip': 10,
    'left_knee': 11,
    'left_ankle': 12,
    'right_knee': 13,
    'right_ankle': 14,
    'left_eye': 15,
    'nose': 16,
    'right_eye': 17,
    'right_ear': 18,
    'left_ear': 19
}

# üìè Ï∏°Ï†ïÌï† Í∞ÅÎèÑ ÌÉÄÍ≤üÎì§ (ÏûêÏÑ∏ Î∂ÑÏÑù)
angle_targets = {
    'Neck bent': ('neck1', 'neck2', 'back1'),
    'Back bent': ('neck2', 'waist', 'back2'),
    'Leg twist': ('left_hip', 'right_hip', 'right_knee')
}

# ÏÇ¨Îûå Ïó¨Îü¨Î™ÖÏùº Îïå, ÌîÑÎ†àÏûÑ Ï§ëÏïôÏóê Í∞ÄÏû• Í∞ÄÍπåÏö¥ ÏÇ¨Îûå Ïù∏Îç±Ïä§ ÏÑ†ÌÉù Ìó¨Ìçº
def get_center_person_index(result, frame_width):
    """
    result: ultralytics result for one frame (results[0])
    frame_width: frame width in pixels
    """
    # ÏïàÏ†Ñ Ï≤¥ÌÅ¨
    if result is None:
        return None
    # prefer keypoints if available
    kps_obj = getattr(result, "keypoints", None)
    if kps_obj is None:
        # fallback: try boxes
        boxes = getattr(result, "boxes", None)
        if boxes is None or len(boxes) == 0:
            return None
        # use box centers
        centers = []
        for b in boxes:
            try:
                # b.xyxy or b.xywh? try xyxy
                xyxy = b.xyxy[0].cpu().numpy() if hasattr(b, "xyxy") else None
            except Exception:
                xyxy = None
            if xyxy is not None:
                cx = (xyxy[0] + xyxy[2]) / 2.0
                centers.append(cx)
        if not centers:
            return 0
        frame_center = frame_width / 2.0
        idx = int(np.argmin([abs(c - frame_center) for c in centers]))
        return idx

    # keypoints present
    # keypoints.data is expected: (n_persons, k*3) or similar; try safe extraction
    try:
        data = kps_obj.data  # tensor maybe
    except Exception:
        # some versions: kps_obj.xy or kps_obj.xys
        try:
            data = kps_obj.xyn  # try normalized
        except Exception:
            return 0

    try:
        # data shape (n, k, 3) or (n, k*3)
        arr = data.cpu().numpy()
        if arr.ndim == 3:
            persons = arr.shape[0]
            mean_x = []
            for i in range(persons):
                # arr[i,:,0] are x coords
                xs = arr[i,:,0]
                mean_x.append(xs.mean())
        elif arr.ndim == 2:
            # flatten form: (n, k*3)
            persons = arr.shape[0]
            k3 = arr.shape[1]
            k = k3 // 3
            mean_x = []
            for i in range(persons):
                xs = arr[i, 0::3]
                mean_x.append(xs.mean())
        else:
            return 0
        # convert normalized -> pixel
        mean_x_px = [mx * frame_width for mx in mean_x]
        frame_center = frame_width / 2.0
        idx = int(np.argmin([abs(mx - frame_center) for mx in mean_x_px]))
        return idx
    except Exception:
        return 0

# üîç Ïã§ÏãúÍ∞Ñ Î∂ÑÏÑù Î£®ÌîÑ (ÏàòÏ†ï: Îì§Ïó¨Ïì∞Í∏∞ Í≥†Ïπ®)
while cap.isOpened():
    success, frame = cap.read()
    if not success:
        break

    # YOLOv8 Î™®Îç∏Ïóê ÌîÑÎ†àÏûÑ Ï†ÑÎã¨ (pose Î™®Îç∏Ïù¥ÎùºÎ©¥ Í≤∞Í≥ºÏóê keypoints Ìè¨Ìï®)
    # model(frame) -> list of Results; take first
    try:
        results = model(frame)  # returns list-like
        if results is None or len(results) == 0:
            cv2.imshow('Posture Detection', frame)
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
            continue
        res0 = results[0]
    except Exception as e:
        print("model inference error:", e)
        break

    frame_width = frame.shape[1]
    target_idx = get_center_person_index(res0, frame_width)

    pose_kps = None
    # ÏïàÏ†ÑÌïòÍ≤å keypoints Ï∂îÏ∂ú
    if hasattr(res0, "keypoints") and getattr(res0, "keypoints") is not None:
        try:
            # .data expected
            pose_kps = res0.keypoints.data  # tensor (n, k, 3) or (n, k*3)
        except Exception:
            try:
                pose_kps = res0.keypoints.cpu().numpy()
            except Exception:
                pose_kps = None

    if pose_kps is not None:
        # get chosen person's keypoints as numpy (k,3)
        try:
            arr = pose_kps.cpu().numpy() if hasattr(pose_kps, "cpu") else np.array(pose_kps)
            # normalize shape
            if arr.ndim == 3:
                person_kp = arr[target_idx]
            elif arr.ndim == 2:
                # (n, k*3) -> reshape
                k = arr.shape[1] // 3
                person_kp = arr[target_idx].reshape(k, 3)
            else:
                person_kp = None
        except Exception:
            person_kp = None
    else:
        person_kp = None

    def get_point(name):
        idx = keypoint_index.get(name)
        if person_kp is None or idx is None or idx >= person_kp.shape[0]:
            return None
        x, y, conf = person_kp[idx]
        if conf <= 0.3:
            return None
        return int(x), int(y)

    # ‚úÖ ÏÑ† Ïó∞Í≤∞
    for kp1, kp2 in skeleton:
        pt1, pt2 = get_point(kp1), get_point(kp2)
        if pt1 and pt2:
            cv2.line(frame, pt1, pt2, (0, 255, 0), 2)

    # ‚úÖ Í∞ÅÎèÑ Ï∏°Ï†ï (deg ÌëúÏãú)
    y_offset = 30
    for label, (a, b, c) in angle_targets.items():
        ang = calculate_angle(get_point(a), get_point(b), get_point(c))
        if ang is not None:
            color = (0, 255, 0)
            if label == 'Neck bent' and ang < 30:
                color = (0, 0, 255)
            if label == 'Back bent' and ang < 40:
                color = (0, 0, 255)
            if label == 'Leg twist' and ang > 150:
                color = (0, 0, 255)
            cv2.putText(frame, f'{label}: {int(ang)} deg', (10, y_offset),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)
            y_offset += 30

    # üñºÔ∏è ÏòÅÏÉÅ Ï∂úÎ†•
    cv2.imshow('Posture Detection', frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
